{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Similarity with using pretrained FaceNet model ### \n",
    "In this document, we will be using **FaceNet** pretrained network to try and build a Face Similarity system. To test out the system, we will be generating 128-d encoded features of 10000 randomly selected celebrities out of almost 100,000 avaliable ones. This data was collected by Microsoft and publicly available at https://exposing.ai/msceleb/. I used only 10,000 images to generate feature encoded database because I only wanted to test out FaceNet's model, but filling the \"celeb images\" folder with rest of available images would surely improve the model performance.\n",
    "\n",
    "*here is one interesting article describing chances of finding doppelgangers/lookalikes somewhere in the world.*\n",
    "https://www.bbc.com/future/article/20160712-you-are-surprisingly-likely-to-have-a-living-doppelganger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "[<KerasTensor: shape=(None, 160, 160, 3) dtype=float32 (created by layer 'input_1')>]\n",
      "[<KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'Bottleneck_BatchNorm')>]\n"
     ]
    }
   ],
   "source": [
    "# example of loading the keras facenet model\n",
    "from keras.models import load_model\n",
    "# load the model\n",
    "model = load_model('facenet_keras.h5/model/facenet_keras.h5')\n",
    "# summarize input and output shape\n",
    "print(model.inputs)\n",
    "print(model.outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "itest = Image.open('images/danielle.png')\n",
    "img = cv2.cvtColor(cv2.imread(\"images/danielle.png\"),cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 96, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 160, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = Image.fromarray(img)\n",
    "image = image.resize((160, 160))\n",
    "img = np.asarray(image)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 160, 160, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = img.astype('float32')\n",
    "# standardize pixel values across channels (global)\n",
    "mean, std = img.mean(), img.std()\n",
    "img = (img - mean) / std\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(img)\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(path):\n",
    "    \"\"\"\n",
    "    Basic custom function to process image\n",
    "    \"\"\"\n",
    "    itest = Image.open(path)\n",
    "    img = cv2.cvtColor(cv2.imread(path),cv2.COLOR_BGR2RGB)\n",
    "    image = Image.fromarray(img)\n",
    "    image = image.resize((160, 160))\n",
    "    img = np.asarray(image)\n",
    "    img = img.astype('float32')\n",
    "    # standardize pixel values across channels (global)\n",
    "    mean, std = img.mean(), img.std()\n",
    "    img = (img - mean) / std\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = {}\n",
    "\n",
    "# First time generating encodings\n",
    "for name in os.listdir('celeb_images/'):\n",
    "    i = int(name.split('.')[0])\n",
    "    database[i] = model.predict(process_img('celeb_images/'+name))\n",
    "    if i%1000==0:\n",
    "        print (\"\\tGenerated \" + str(i) + \" encodings...\")  # KEEP TRACK OF PROGRESS\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving generated database of 128-d encoded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving database object as a JSON so we dont have to generate\n",
    "# encodings when reusing\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "    \n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(database, fp, cls=NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'r') as fp:\n",
    "    database = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_to_string(i):\n",
    "    \"\"\"\n",
    "    Small custom function to convert to proper string form\n",
    "    \"\"\"\n",
    "    s = str(i)\n",
    "    while len(s)!=6:\n",
    "        s = '0'+s\n",
    "        \n",
    "    return s + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = model.predict(process_img('enter_path_to_desired_persons_face'))\n",
    "minV = 1000\n",
    "maxKey = 0\n",
    "\n",
    "print (img)\n",
    "for key, k_img in database.items():\n",
    "    value = np.linalg.norm(k_img-img)\n",
    "    if value < minV:\n",
    "        minV = value\n",
    "        maxKey = key\n",
    "\n",
    "similar = Image.open('celeb_images/' + conv_to_string(maxKey))\n",
    "similar.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, to see some results ### \n",
    "Now, when we implemented this simple Face Similarity Model, let's test it out. For those purposes, I chose a picture of my wonderful friend and compared it to our dataset. \n",
    "<img src=\"test/digi.png\"> <center> V </center> <img src=\"test/garyVee.jpg\">\n",
    "\n",
    "To be honest, I see a quite resemblence between my friend and Gary Vee, especially taking in consideration we have only 10,000 images in our dataset and different possible facial features combinations. Now, you can use this notebook to see which celebrity looks most similar to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's it. This was just a simple notebook to showcase power of Computer Vision, pretrained models and ways to have fun with them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
